{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4WpkGa7hLQb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df=pd.read_csv('train.csv')\n",
        "test_df=pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "5TgVqXY0h64m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FyyOTtEBowV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "zevRrhzVFwoK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "621b017b"
      },
      "source": [
        "# Primitive Data Processing\n",
        "\n",
        "from scipy.stats import zscore\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Check for null values\n",
        "print(\"Missing values in train_df:\")\n",
        "print(train_df.isnull().sum())\n",
        "\n",
        "print(\"\\nMissing values in test_df:\")\n",
        "print(test_df.isnull().sum())\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nPrimitive processing steps checked.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d19e56a"
      },
      "source": [
        "# Examine categorical feature distributions\n",
        "\n",
        "categorical_features = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS']\n",
        "\n",
        "# Determine the number of rows and columns for the grid\n",
        "n_features = len(categorical_features)\n",
        "n_cols = 3  # You can adjust the number of columns as needed\n",
        "n_rows = (n_features + n_cols - 1) // n_cols\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 5))\n",
        "axes = axes.flatten() # Flatten the 2D array of axes for easy iteration\n",
        "\n",
        "for i, feature in enumerate(categorical_features):\n",
        "    sns.countplot(data=train_df, x=feature, order=train_df[feature].value_counts().index, ax=axes[i])\n",
        "    axes[i].set_title(f'Distribution of {feature}')\n",
        "    axes[i].set_xlabel(feature)\n",
        "    axes[i].set_ylabel('Count')\n",
        "    axes[i].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Hide any unused subplots\n",
        "for j in range(i + 1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "duR_s1Drj6uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df=train_df.drop(\"id\",axis='columns')\n",
        "test_df=test_df.drop(\"id\",axis='columns')"
      ],
      "metadata": {
        "id": "tAlpwuTHk5RO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "9f6vBHB4mC2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=train_df.drop(\"WeightCategory\",axis='columns')\n",
        "y=train_df['WeightCategory']"
      ],
      "metadata": {
        "id": "5A3rgXzIp6Er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = ['Age', 'Height','Weight','FCVC','NCP','CH2O','FAF','TUE']"
      ],
      "metadata": {
        "id": "aD3HEyONyg-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bc3f217"
      },
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(train_df[numerical_features].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix of Numerical Features')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = ColumnTransformer(transformers=[\n",
        "    ('t1',OneHotEncoder(drop='first'),['CAEC']),\n",
        "    ('t2',OneHotEncoder(drop='first'),['CALC']),\n",
        "    ('t3', StandardScaler(), numeric_features),\n",
        "\n",
        "    ('t4',OneHotEncoder(drop='first'),['Gender','family_history_with_overweight','FAVC','SMOKE','SCC','MTRANS'])\n",
        "],remainder='passthrough')"
      ],
      "metadata": {
        "id": "Jkp1rIMOq6Fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41cdc79c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd # Import pandas to ensure train_df is accessible\n",
        "\n",
        "# Assuming 'y' is the target variable (WeightCategory)\n",
        "# If y is a pandas Series, we can directly use it, otherwise convert it\n",
        "if not isinstance(y, pd.Series):\n",
        "  y_series = pd.Series(y, name=\"WeightCategory\")\n",
        "else:\n",
        "  y_series = y\n",
        "\n",
        "plt.figure(figsize=(10, 6)) # Adjusted figure size for better readability\n",
        "sns.countplot(data=None, x=y_series, order=y_series.value_counts().index) # Use data=None and pass the series directly, order by count\n",
        "plt.title(\"Class Distribution of Obesity Categories\")\n",
        "plt.xlabel(\"Obesity Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=45, ha='right') # Rotate labels for better readability if many classes\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "999f8c40"
      },
      "source": [
        "numerical_features = ['Age', 'Height','Weight','FCVC','NCP','CH2O','FAF','TUE']\n",
        "\n",
        "train_df[numerical_features].hist(bins=30, figsize=(15, 10))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "304ab0eb"
      },
      "source": [
        "categorical_features = ['Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE', 'SCC', 'CALC', 'MTRANS']\n",
        "target = 'WeightCategory'\n",
        "\n",
        "n_features = len(categorical_features)\n",
        "n_cols = 2\n",
        "n_rows = (n_features + n_cols - 1) // n_cols\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, n_rows * 6)) # Adjust figsize as needed\n",
        "axes = axes.flatten()\n",
        "for i, feature in enumerate(categorical_features):\n",
        "    sns.countplot(data=train_df, x=feature, hue=target, palette='viridis', ax=axes[i])\n",
        "    axes[i].set_title(f'Relationship between {feature} and {target}')\n",
        "    axes[i].set_xlabel(feature)\n",
        "    axes[i].set_ylabel('Count')\n",
        "    axes[i].tick_params(axis='x', rotation=45)\n",
        "    axes[i].legend(title=target)\n",
        "\n",
        "for j in range(i + 1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9304e82a"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('train.csv')\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=train_df, x='WeightCategory', order=train_df['WeightCategory'].value_counts().index)\n",
        "plt.title('Distribution of WeightCategory')\n",
        "plt.xlabel('Weight Category')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array(y)\n",
        "y.shape"
      ],
      "metadata": {
        "id": "mHEDR5VMjLs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import numpy as np\n",
        "\n",
        "encoder = OrdinalEncoder()\n",
        "y_encoded = encoder.fit_transform(np.array(y).reshape(-1, 1))\n",
        "y_encoded.shape"
      ],
      "metadata": {
        "id": "nLfKnDOfzT7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "5OcIK4_tmJp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 460, 480),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.065),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 6),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 2, 5),\n",
        "        'gamma': trial.suggest_float('gamma', 0.2, 0.4),\n",
        "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.8),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0.4, 0.6),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 0.5),\n",
        "    }\n",
        "\n",
        "    model = XGBClassifier(**params, objective='multi:softmax')\n",
        "\n",
        "    # cross-validation\n",
        "    score = cross_val_score(model, x_transformed, y_encoded, cv=3, scoring='accuracy').mean() # Use original y\n",
        "\n",
        "    return score\n"
      ],
      "metadata": {
        "id": "fZrXe6zcph2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_transformed = transformer.fit_transform(x)"
      ],
      "metadata": {
        "id": "MnFNUvVVzFON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "\n",
        "# Encode y to int\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded_labels = label_encoder.fit_transform(y)\n",
        "\n",
        "# 100 trials optimization - 50 and 25 didnt yeild the same performance\n",
        "study.optimize(lambda trial: objective(trial), n_trials=100, show_progress_bar=True)\n",
        "\n",
        "# Print the best hyperparameters and the best score\n",
        "\n",
        "print(\"Best hyperparameters:\", study.best_params)\n",
        "print(\"Best accuracy:\", study.best_value)\n",
        "# best_params={'n_estimators': 476,  'learning_rate': 0.056175675016670416, 'max_depth': 4, 'min_child_weight': 2, 'gamma': 0.3354617624351886, 'subsample': 0.7871797069127701, 'colsample_bytree': 0.5071468557602662, 'reg_alpha': 0.5393018307093757, 'reg_lambda': 0.0809287158560023}\n",
        "final_model = XGBClassifier(**study.best_params, random_state=42, objective='multi:softmax', num_class=len(label_encoder.classes_))\n",
        "final_model.fit(x_transformed, y_encoded_labels)\n",
        "\n",
        "# Make predictions on the training data to evaluate accuracy\n",
        "y_pred = final_model.predict(x_transformed)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_encoded_labels, y_pred)\n",
        "print(f\"Accuracy on the training data: {accuracy}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ZHH8wFIxFljD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# fit transform predict\n",
        "x_transformed = transformer.fit_transform(x)\n",
        "test_transformed = transformer.transform(test_df)\n",
        "test_predictions_encoded = final_model.predict(test_transformed)\n",
        "\n",
        "# decode\n",
        "test_predictions = encoder.inverse_transform(test_predictions_encoded.reshape(-1, 1))\n",
        "\n",
        "# submission\n",
        "submission_df = pd.DataFrame({'id': test_df.index + 15533, 'Weight_Category': test_predictions.flatten()})\n",
        "submission_df.to_csv('xgb_optuna.csv', index=False)\n",
        "\n",
        "print(\"xgb_optuna.csv created successfully with predictions from the optimized model!\")"
      ],
      "metadata": {
        "id": "1yJBZ0n-Eb5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7abe89bc"
      },
      "source": [
        "numerical_features = ['Age', 'Height','Weight','FCVC','NCP','CH2O','FAF','TUE']\n",
        "target = 'WeightCategory'\n",
        "\n",
        "for feature in numerical_features:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.boxplot(data=train_df, x=target, y=feature, order=train_df[target].value_counts().index)\n",
        "    plt.title(f'{feature} vs {target}')\n",
        "    plt.xlabel(target)\n",
        "    plt.ylabel(feature)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}