{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import warnings\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "# Suppress warnings for a cleaner notebook\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "u1nZDM5RYx2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "x63geBhVYy_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Load Data ---\n",
        "print(\"Loading data...\")\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/ML PROJECT/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/ML PROJECT/test.csv\")\n",
        "sample_submission_df = pd.read_csv(\"/content/drive/MyDrive/ML PROJECT/sample_submission.csv\")\n",
        "\n",
        "\n",
        "print(\"Data loaded successfully.\")\n",
        "print(\"\\n--- Training Data Info ---\")\n",
        "train_df.info()\n",
        "\n",
        "print(\"\\n--- Training Data Head ---\")\n",
        "print(train_df.head())\n",
        "\n",
        "\n",
        "\n",
        "# --- 2. Data Preprocessing ---\n",
        "print(\"\\nStarting preprocessing...\")\n",
        "\n",
        "# Store test IDs for final submission\n",
        "test_ids = test_df['id']\n",
        "\n",
        "# Separate target variable (y) from training features (X)\n",
        "y = train_df['WeightCategory']\n",
        "X = train_df.drop(columns=['id', 'WeightCategory'])\n",
        "\n",
        "# Store test features (X_test)\n",
        "X_test = test_df.drop(columns=['id'])\n",
        "\n",
        "# --- 2a. Encode the Target Variable (y) ---\n",
        "# We convert text labels (e.g., 'Normal_Weight') into numbers (0, 1, 2...)\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "num_classes = len(le.classes_)\n",
        "print(f\"\\nTarget variable encoded into {num_classes} classes.\")\n",
        "print(f\"Classes: {le.classes_}\")\n",
        "\n",
        "# --- 2b. One-Hot Encoding for Categorical Features ---\n",
        "# Get list of categorical columns (those with 'object' dtype)\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "print(f\"Categorical features to encode: {list(categorical_cols)}\")\n",
        "\n",
        "# We combine train and test to ensure they have the exact same dummy columns\n",
        "combined_df = pd.concat([X, X_test], axis=0)\n",
        "combined_df_processed = pd.get_dummies(combined_df, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# Separate back into X and X_test\n",
        "X_processed = combined_df_processed.iloc[:len(X)]\n",
        "X_test_processed = combined_df_processed.iloc[len(X):]\n",
        "\n",
        "print(f\"Original feature count: {len(X.columns)}\")\n",
        "print(f\"Processed feature count after one-hot encoding: {len(X_processed.columns)}\")"
      ],
      "metadata": {
        "id": "w4Y8Y_rIY12L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KOtxeCWoY-Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaUhGMTKYsu6"
      },
      "outputs": [],
      "source": [
        "# --- 3. Model Training & Validation ---\n",
        "print(\"\\nSplitting data for training and validation...\")\n",
        "\n",
        "# Split the *processed* training data into a new training set and a validation set\n",
        "# This lets us check our model's performance on data it hasn't seen\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_processed,\n",
        "    y_encoded,\n",
        "    test_size=0.2,      # 20% for validation\n",
        "    random_state=42,    # For reproducible results\n",
        "    stratify=y_encoded  # Ensures class distribution is the same in train and val\n",
        ")\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Validation set shape: {X_val.shape}\")\n",
        "\n",
        "print(\"\\n--- Starting XGBoost Model Training ---\")\n",
        "\n",
        "# Initialize the XGBoost Classifier\n",
        "# You can tune hyperparameters like n_estimators, learning_rate, max_depth, etc.\n",
        "model = xgb.XGBClassifier(objective='multi:softmax',  # For multi-class classification\n",
        "                          num_class=num_classes,      # Number of target classes\n",
        "                          n_estimators=100,           # Number of boosting rounds\n",
        "                          learning_rate=0.1,          # Step size shrinkage\n",
        "                          max_depth=5,                # Maximum depth of trees\n",
        "                          random_state=42,            # For reproducible results\n",
        "                          use_label_encoder=False,    # Recommended for newer versions\n",
        "                          eval_metric='mlogloss')     # Evaluation metric\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"--- Model Training Complete ---\")\n",
        "\n",
        "# --- 4. Model Evaluation ---\n",
        "print(\"\\n--- Model Evaluation on Validation Set ---\")\n",
        "# Predict on the validation set\n",
        "y_pred_val = model.predict(X_val)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred_val)\n",
        "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(\"\\nClassification Report (Validation):\")\n",
        "# Print classification report with original text labels\n",
        "print(classification_report(y_val, y_pred_val, target_names=le.classes_))\n",
        "\n",
        "# --- 5. Final Prediction & Submission ---\n",
        "print(\"\\n--- Generating Final Submission File ---\")\n",
        "\n",
        "# Now, we train a new model on the *ENTIRE* training dataset\n",
        "# This ensures the model learns from all available data\n",
        "print(\"Training final model on all data...\")\n",
        "final_model = xgb.XGBClassifier(objective='multi:softmax',\n",
        "                                num_class=num_classes,\n",
        "                                n_estimators=100,\n",
        "                                learning_rate=0.1,\n",
        "                                max_depth=5,\n",
        "                                random_state=42, # For reproducible results\n",
        "                                use_label_encoder=False,\n",
        "                                eval_metric='mlogloss')\n",
        "final_model.fit(X_processed, y_encoded)\n",
        "print(\"Final model trained.\")\n",
        "\n",
        "# Make predictions on the processed test data\n",
        "test_predictions_encoded = final_model.predict(X_test_processed)\n",
        "\n",
        "# Convert the numeric predictions back to their original text labels\n",
        "test_predictions = le.inverse_transform(test_predictions_encoded)\n",
        "\n",
        "# Create the submission DataFrame\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_ids,\n",
        "    'WeightCategory': test_predictions\n",
        "})\n",
        "\n",
        "# Save the submission file\n",
        "submission_df.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"\\n--- Submission File Created! ---\")\n",
        "print(\"File 'submission.csv' is ready.\")\n",
        "print(submission_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c779b366"
      },
      "source": [
        "# from sklearn.model_selection import StratifiedKFold\n",
        "# from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# # --- 6. K-Fold Cross-Validation ---\n",
        "# print(\"\\n--- Starting K-Fold Cross-Validation ---\")\n",
        "\n",
        "# # Define the number of folds (k)\n",
        "# n_splits = 5 # You can change this number\n",
        "\n",
        "# # Initialize StratifiedKFold\n",
        "# skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# # Lists to store evaluation results from each fold\n",
        "# fold_accuracies = []\n",
        "# fold_reports = []\n",
        "\n",
        "# # Iterate over each fold\n",
        "# for fold, (train_index, val_index) in enumerate(skf.split(X_processed, y_encoded)):\n",
        "#     print(f\"\\n--- Fold {fold+1}/{n_splits} ---\")\n",
        "\n",
        "#     # Split data into training and validation sets for the current fold\n",
        "#     X_train_fold, X_val_fold = X_processed.iloc[train_index], X_processed.iloc[val_index]\n",
        "#     y_train_fold, y_val_fold = y_encoded[train_index], y_encoded[val_index]\n",
        "\n",
        "#     # Initialize a new XGBoost model for each fold\n",
        "#     # Using the same hyperparameters as before\n",
        "#     fold_model = xgb.XGBClassifier(objective='multi:softmax',\n",
        "#                                    num_class=num_classes,\n",
        "#                                    n_estimators=100,\n",
        "#                                    learning_rate=0.1,\n",
        "#                                    max_depth=5,\n",
        "#                                    random_state=42, # Keep random_state for reproducibility within each fold\n",
        "#                                    use_label_encoder=False,\n",
        "#                                    eval_metric='mlogloss')\n",
        "\n",
        "#     # Train the model on the training data for the current fold\n",
        "#     fold_model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "#     # Predict on the validation data for the current fold\n",
        "#     y_pred_fold = fold_model.predict(X_val_fold)\n",
        "\n",
        "#     # Evaluate the model on the validation data for the current fold\n",
        "#     fold_accuracy = accuracy_score(y_val_fold, y_pred_fold)\n",
        "#     fold_report = classification_report(y_val_fold, y_pred_fold, target_names=le.classes_)\n",
        "\n",
        "#     print(f\"Fold {fold+1} Validation Accuracy: {fold_accuracy * 100:.2f}%\")\n",
        "#     # print(f\"Fold {fold+1} Classification Report:\\n{fold_report}\") # Uncomment to see report for each fold\n",
        "\n",
        "#     # Store the results\n",
        "#     fold_accuracies.append(fold_accuracy)\n",
        "#     fold_reports.append(fold_report)\n",
        "\n",
        "# # --- Summarize Cross-Validation Results ---\n",
        "# print(\"\\n--- Cross-Validation Summary ---\")\n",
        "# print(f\"Average Validation Accuracy across {n_splits} folds: {np.mean(fold_accuracies) * 100:.2f}%\")\n",
        "# print(f\"Standard Deviation of Validation Accuracy: {np.std(fold_accuracies) * 100:.2f}%\")\n",
        "\n",
        "# # Note: For a final model to use for prediction on the test set,\n",
        "# # you would typically train on the entire training dataset (X_processed, y_encoded)\n",
        "# # after determining the best hyperparameters (potentially using cross-validation).\n",
        "# # The code for the final model training and submission (Section 5) remains the same\n",
        "# # as it uses the entire training data.\n",
        "\n",
        "# print(\"\\nK-Fold Cross-Validation Complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2c829aa"
      },
      "source": [
        "# Task\n",
        "Perform hyperparameter tuning for the XGBoost model using cross-validation to find the best parameters for improved accuracy and then evaluate the model on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "480c8dcf"
      },
      "source": [
        "## Define hyperparameter search space\n",
        "\n",
        "### Subtask:\n",
        "Determine the range of values for the XGBoost hyperparameters that you want to explore (e.g., `n_estimators`, `learning_rate`, `max_depth`, etc.).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91e42588"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the hyperparameter search space for XGBoost based on common tuning practices and the problem context.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2238b461"
      },
      "source": [
        "# --- 7. Hyperparameter Tuning Setup ---\n",
        "print(\"\\n--- Setting up Hyperparameter Tuning ---\")\n",
        "\n",
        "# Define the hyperparameter search space for XGBoost\n",
        "# We'll explore a few key parameters\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],  # Number of boosting rounds\n",
        "    'learning_rate': [0.01, 0.1, 0.2], # Step size shrinkage\n",
        "    'max_depth': [3, 5, 7],           # Maximum depth of trees\n",
        "    'subsample': [0.8, 1.0],          # Fraction of samples used per tree\n",
        "    'colsample_bytree': [0.8, 1.0],   # Fraction of features used per tree\n",
        "    'gamma': [0, 0.1, 0.2]            # Minimum loss reduction required to make a further partition\n",
        "}\n",
        "\n",
        "print(\"Hyperparameter search space defined:\")\n",
        "print(param_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48a1fe74"
      },
      "source": [
        "## Choose tuning method\n",
        "\n",
        "### Subtask:\n",
        "Decide whether to use Grid Search (exhaustive search) or Randomized Search (random sampling) for exploring the hyperparameter space. Randomized Search is often preferred for larger search spaces as it's computationally less expensive.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d76791d3"
      },
      "source": [
        "**Reasoning**:\n",
        "Based on the defined hyperparameter search space and considering computational efficiency, I will decide whether to use GridSearchCV or RandomizedSearchCV and document the choice.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98169d88"
      },
      "source": [
        "# --- 8. Choose Tuning Method ---\n",
        "print(\"\\n--- Choosing Hyperparameter Tuning Method ---\")\n",
        "\n",
        "# Analyze the size of the search space:\n",
        "# n_estimators: 3 values\n",
        "# learning_rate: 3 values\n",
        "# max_depth: 3 values\n",
        "# subsample: 2 values\n",
        "# colsample_bytree: 2 values\n",
        "# gamma: 3 values\n",
        "# Total combinations = 3 * 3 * 3 * 2 * 2 * 3 = 162\n",
        "\n",
        "# The search space has 162 combinations. While not extremely large,\n",
        "# considering the number of folds in cross-validation (e.g., 5 folds),\n",
        "# GridSearchCV would train 162 * 5 = 810 models.\n",
        "# RandomizedSearchCV is generally more efficient for exploring a large search space\n",
        "# and can often find a good set of hyperparameters more quickly.\n",
        "# Given the moderate size and the potential for faster exploration,\n",
        "# RandomizedSearchCV is a suitable choice.\n",
        "\n",
        "chosen_method = \"RandomizedSearchCV\"\n",
        "justification = (\n",
        "    \"The hyperparameter search space, while not massive (162 combinations), \"\n",
        "    \"is large enough that exploring every combination with GridSearchCV \"\n",
        "    \"across multiple cross-validation folds would be computationally intensive. \"\n",
        "    \"RandomizedSearchCV allows for efficient exploration of the space by sampling \"\n",
        "    \"a fixed number of combinations, which is likely to find a good set of parameters \"\n",
        "    \"more quickly than an exhaustive search.\"\n",
        ")\n",
        "\n",
        "print(f\"Chosen Hyperparameter Tuning Method: {chosen_method}\")\n",
        "print(f\"Justification: {justification}\")\n",
        "\n",
        "# This step is for documentation and planning, no code execution required for tuning yet."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b457c4e"
      },
      "source": [
        "[link text](https://)**Reasoning**:\n",
        "The decision to use RandomizedSearchCV has been made. The next step is to implement the hyperparameter tuning using RandomizedSearchCV with cross-validation on the training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86c9924a"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold # Import StratifiedKFold\n",
        "\n",
        "print(\"\\n--- Starting Randomized Search (with Cross-Validation) for Hyperparameter Tuning ---\")\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "# n_iter: number of parameter settings that are sampled.\n",
        "# Increase this for a more exhaustive search, decrease for faster execution.\n",
        "n_iter_search = 50 # Sampling 50 combinations out of 162\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 5 # You can change this number\n",
        "\n",
        "# Initialize StratifiedKFold for cross-validation\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb.XGBClassifier(objective='multi:softmax',\n",
        "                                num_class=num_classes,\n",
        "                                random_state=42,\n",
        "                                use_label_encoder=False,\n",
        "                                eval_metric='mlogloss'), # Pass base estimator without tuned params\n",
        "    param_distributions=param_grid, # The grid defined earlier\n",
        "    n_iter=n_iter_search,           # Number of combinations to sample\n",
        "    scoring='accuracy',             # Metric to optimize\n",
        "    cv=skf,                         # Use StratifiedKFold for cross-validation\n",
        "    verbose=1,                      # Show progress\n",
        "    random_state=42,                # For reproducible sampling\n",
        "    n_jobs=-1                       # Use all available cores\n",
        ")\n",
        "\n",
        "# Fit RandomizedSearchCV on the *entire* processed training data (including BMI)\n",
        "# Cross-validation will handle the splitting internally during the search\n",
        "random_search.fit(X_processed, y_encoded)\n",
        "\n",
        "print(\"\\n--- Randomized Search Complete ---\")\n",
        "\n",
        "# --- Get the best parameters and best score ---\n",
        "print(\"\\nBest parameters found:\")\n",
        "print(random_search.best_params_)\n",
        "\n",
        "# The best_score_ here is the average cross-validation score\n",
        "print(f\"\\nAverage cross-validation accuracy with best parameters: {random_search.best_score_ * 100:.2f}%\")\n",
        "\n",
        "# The best model found by RandomizedSearchCV is available at random_search.best_estimator_\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# --- 5. Final Prediction & Submission (using the best parameters and entire data) ---\n",
        "print(\"\\n--- Generating Final Submission File (with tuned parameters) ---\")\n",
        "\n",
        "# Train a final model on the *entire* training dataset using the best parameters found\n",
        "print(\"Training final model on all data with best parameters...\")\n",
        "final_model_tuned = xgb.XGBClassifier(objective='multi:softmax',\n",
        "                                      num_class=num_classes,\n",
        "                                      random_state=42,\n",
        "                                      use_label_encoder=False,\n",
        "                                      eval_metric='mlogloss',\n",
        "                                      **random_search.best_params_) # Use the best parameters\n",
        "\n",
        "# Train on the entire processed training data (including BMI)\n",
        "final_model_tuned.fit(X_processed, y_encoded)\n",
        "print(\"Final model trained with best parameters.\")\n",
        "\n",
        "# Make predictions on the processed test data (including BMI) using the final tuned model\n",
        "test_predictions_encoded_tuned = final_model_tuned.predict(X_test_processed)\n",
        "\n",
        "# Convert the numeric predictions back to their original text labels\n",
        "test_predictions_tuned = le.inverse_transform(test_predictions_encoded_tuned)\n",
        "\n",
        "# Create the submission DataFrame with tuned predictions\n",
        "submission_df_tuned = pd.DataFrame({\n",
        "    'id': test_ids,\n",
        "    'WeightCategory': test_predictions_tuned\n",
        "})\n",
        "\n",
        "# Save the submission file with a clear name indicating tuning and CV\n",
        "submission_df_tuned.to_csv(\"submission_tuned_cv_final.csv\", index=False)\n",
        "\n",
        "print(\"\\n--- Tuned Submission File Created! (with Cross-Validation) ---\")\n",
        "print(\"File 'submission_tuned_cv_final.csv' is ready.\")\n",
        "print(submission_df_tuned.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcaf7383"
      },
      "source": [
        "# --- Feature Engineering: Calculate BMI ---\n",
        "print(\"\\n--- Calculating BMI ---\")\n",
        "\n",
        "# Calculate BMI for the processed combined dataframe\n",
        "# BMI = Weight (kg) / [Height (m)]^2\n",
        "# Assuming Height is in meters and Weight in kg as per common standards and column names\n",
        "combined_df_processed['BMI'] = combined_df_processed['Weight'] / (combined_df_processed['Height']**2)\n",
        "\n",
        "print(\"BMI calculated and added as a new feature.\")\n",
        "\n",
        "# Separate the data back into X_processed and X_test_processed with the new BMI feature\n",
        "X_processed = combined_df_processed.iloc[:len(X)]\n",
        "X_test_processed = combined_df_processed.iloc[len(X):]\n",
        "\n",
        "print(f\"Processed feature count after adding BMI: {len(X_processed.columns)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afca3d9f"
      },
      "source": [
        "## Interpret Feature Importance and Summarize Findings\n",
        "\n",
        "### Subtask:\n",
        "Analyze the generated feature importance plot and the sorted feature importance list to identify the most influential features in the model's predictions. Summarize the key findings from the hyperparameter tuning process and the feature importance analysis. Discuss the performance of the final tuned model.\n",
        "\n",
        "**Reasoning**:\n",
        "Interpreting the feature importance helps in understanding the model's decision-making process and identifying which input variables have the strongest relationship with the target variable (Weight Category). Summarizing the findings provides a clear overview of the project's results, including the impact of hyperparameter tuning and the insights gained from feature analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33591449"
      },
      "source": [
        "## Summary of Findings\n",
        "\n",
        "Based on the feature importance analysis, the most important features for predicting Weight Category using the tuned XGBoost model are:\n",
        "\n",
        "1.  **BMI**: As expected, Body Mass Index is the most significant predictor of Weight Category. This aligns with the definition of weight categories often being based on BMI ranges.\n",
        "2.  **Gender_Male**: The gender of an individual is the second most important feature, suggesting a notable difference in weight category distribution between males and females in this dataset.\n",
        "3.  **Weight**: While BMI is a combined measure, the individual weight of a person is also a strong predictor.\n",
        "4.  **FCVC (Frequency of consumption of vegetables)**: This feature related to dietary habits shows significant importance, indicating that vegetable consumption frequency is a key factor in determining weight category.\n",
        "5.  **FAVC_yes (Frequent consumption of high caloric food - yes)**: This also highlights the importance of dietary choices, specifically the consumption of high-calorie foods.\n",
        "\n",
        "Other features like `CALC_no` (Consumption of alcohol - no), `CH2O` (Consumption of water daily), `CAEC_no` (Consumption of food between meals - no), and `CAEC_Frequently` (Consumption of food between meals - frequently) also show notable importance, emphasizing the role of various lifestyle and dietary factors.\n",
        "\n",
        "**Hyperparameter Tuning and Model Performance:**\n",
        "\n",
        "The Randomized Search with 5-fold cross-validation explored 50 different hyperparameter combinations. The best parameters found were:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de1bdca1"
      },
      "source": [
        "# --- Analyze Feature Importance of the Final Tuned Model ---\n",
        "print(\"\\n--- Analyzing Feature Importance of the Final Tuned Model ---\")\n",
        "\n",
        "# Get feature importances from the final tuned model\n",
        "feature_importances = final_model_tuned.feature_importances_\n",
        "\n",
        "# Get the names of the features from the processed training data\n",
        "feature_names = X_processed.columns\n",
        "\n",
        "# Create a pandas Series for easier handling and sorting\n",
        "importance_series = pd.Series(feature_importances, index=feature_names)\n",
        "\n",
        "# Sort the features by importance in descending order\n",
        "sorted_importance_series = importance_series.sort_values(ascending=False)\n",
        "\n",
        "# Print the sorted feature importances\n",
        "print(\"Feature Importances (Sorted):\")\n",
        "print(sorted_importance_series)\n",
        "\n",
        "# Optional: Visualize the feature importances\n",
        "plt.figure(figsize=(12, 7))\n",
        "sorted_importance_series.plot(kind='bar')\n",
        "plt.title('Feature Importance from Final Tuned XGBoost Model')\n",
        "plt.ylabel('Importance')\n",
        "plt.xlabel('Features')\n",
        "plt.xticks(rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n--- Feature Importance Analysis Complete ---\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a-c6fXFT7zYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d45d03d"
      },
      "source": [
        "# --- 9. Analyze Feature Importance ---\n",
        "print(\"\\n--- Analyzing Feature Importance of the Best Model ---\")\n",
        "\n",
        "# Get feature importances from the best model\n",
        "feature_importances = best_model.feature_importances_\n",
        "\n",
        "# Get the names of the features\n",
        "# The order of feature_importances_ corresponds to the order of columns in X_processed\n",
        "feature_names = X_processed.columns\n",
        "\n",
        "# Create a pandas Series for easier handling and sorting\n",
        "importance_series = pd.Series(feature_importances, index=feature_names)\n",
        "\n",
        "# Sort the features by importance in descending order\n",
        "sorted_importance_series = importance_series.sort_values(ascending=False)\n",
        "\n",
        "# Print the sorted feature importances\n",
        "print(\"Feature Importances (Sorted):\")\n",
        "print(sorted_importance_series)\n",
        "\n",
        "# Optional: Visualize the feature importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "sorted_importance_series.plot(kind='bar')\n",
        "plt.title('Feature Importance from XGBoost Model')\n",
        "plt.ylabel('Importance')\n",
        "plt.xlabel('Features')\n",
        "plt.xticks(rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n--- Feature Importance Analysis Complete ---\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lhu7zf9WdhbT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}